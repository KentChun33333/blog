{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Bot \n",
    "\n",
    "### Overview\n",
    "- Introduction \n",
    "- Data ETL\n",
    "- Data Augmentation \n",
    "- Networks Architecture \n",
    "- Training \n",
    "- Model Averaging \n",
    "- Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmp75npfs/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmp75npfs/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is disabled, cuDNN 5103)\n",
      "C:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# model build \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conf:\n",
    "    def __init__(self, confPath):\n",
    "        # load and store the configuration and update the object's dictionary\n",
    "        conf = json.loads(open(confPath).read())\n",
    "        self.__dict__.update(conf)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        # return the value associated with the supplied key\n",
    "        return self.__dict__.get(k, None)\n",
    "    \n",
    "    \n",
    "def auto_resized(img,size):\n",
    "    '''size = (width,height)'''\n",
    "    size = tuple(size)\n",
    "    resize_img = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "    return resize_img\n",
    "\n",
    "def TrainFilePath(folderPath, constrain=None, **kargs):\n",
    "    '''\n",
    "    (1) Output filepath and calssName\n",
    "    (2) folderPath \n",
    "          --label_1\n",
    "           -- xxx.jpg\n",
    "    '''\n",
    "    assert folderPath[-1]!='/'\n",
    "    if constrain is None:\n",
    "        constrain = ('avi', 'mp4','png','jpg') \n",
    "    for (rootDir, dirNames, fileNames) in os.walk(folderPath):\n",
    "        for fileName in fileNames:\n",
    "            if fileName.split('.')[-1] in constrain:\n",
    "                yield (os.path.join(rootDir, fileName)) \n",
    "                \n",
    "#img_channels = 3\n",
    "def genTrX(filePath, resolution, img_channels=3):\n",
    "    assert type(resolution) == tuple\n",
    "    img = auto_resized(imread(filePath),resolution)  #conf['sliding_size']\n",
    "    if img_channels==1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img_channels==3:\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "                \n",
    "def load_training(folderList, img_rows, img_cols, img_channels):\n",
    "    TrY = []\n",
    "    TrX = []\n",
    "    TrY_template = np.eye(len(folderList))\n",
    "    for eyeId, folderPath in enumerate(folderList):\n",
    "        for imgPath in TrainFilePath(folderPath) :\n",
    "            TrY.append(TrY_template[eyeId])\n",
    "            TrX.append(genTrX(imgPath, (img_rows,img_cols), img_channels))\n",
    "    print (len(TrX))\n",
    "    return TrX, TrY\n",
    "\n",
    "def create_folderList(rootDir):\n",
    "    result=[]\n",
    "    for a in os.listdir(rootDir):\n",
    "        a = os.path.join(rootDir, a)\n",
    "        if os.path.isdir(a):\n",
    "            result.append(a) \n",
    "    return result\n",
    "\n",
    "\n",
    "def reshapeShuffle(TrX, TrY, img_rows, img_cols, img_channels):\n",
    "    trainX = np.asarray(TrX, dtype = np.uint8)\n",
    "    trainX = trainX.reshape(trainX.shape[0], img_channels, img_rows, img_cols)\n",
    "    trainX = trainX.astype('float32')\n",
    "    trainY = np.asarray(TrY, dtype = np.float32)\n",
    "    # shuffle\n",
    "    trainX , trainY = shuffle(trainX,trainY)\n",
    "    print ('Train_X : ',trainX.shape,'Train_Y' ,trainY.shape)\n",
    "    return trainX , trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116481\n"
     ]
    }
   ],
   "source": [
    "ROOT_Dir = 'D:\\\\2016bot_cv'\n",
    "\n",
    "img_rows= 32\n",
    "\n",
    "img_cols= 32\n",
    "\n",
    "img_channels=3\n",
    "\n",
    "folderList = create_folderList(ROOT_Dir)\n",
    "\n",
    "Train_X, Train_Y = load_training(folderList, img_rows, img_cols, img_channels)\n",
    "\n",
    "\n",
    "\n",
    "#TrainFilePath('D:\\2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train_X : ', (116481L, 3L, 52L, 52L), 'Train_Y', (116481L, 12L))\n"
     ]
    }
   ],
   "source": [
    "train_X , train_Y = reshapeShuffle(Train_X, Train_Y, img_rows, img_cols, img_channels=img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_Img = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_Img.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def VGG_19(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5600, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5600, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(550, activation='softmax'))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simpleVGG(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def easyVGG(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(32, 3, 2, activation='relu'))\n",
    "    model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 2, activation='relu'))\n",
    "    model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(480, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_53 (ZeroPadding2D) (None, 3, 54, 54)     0           zeropadding2d_input_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 32, 52, 53)    608         zeropadding2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_38 (MaxPooling2D)   (None, 32, 25, 26)    0           convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 64, 23, 25)    12352       maxpooling2d_38[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_39 (MaxPooling2D)   (None, 64, 11, 12)    0           convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)             (None, 8448)          0           maxpooling2d_39[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 480)           4055520     flatten_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 480)           0           dense_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 120)           57720       dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 120)           0           dense_65[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_66 (Dense)                 (None, 12)            1452        dropout_25[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 4127652\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = VGG_19(img_rows,img_cols)\n",
    "model = easyVGG(img_rows,img_cols)\n",
    "#https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "sgd = SGD(lr=0.1, decay=1e-3, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93184/93184 [==============================] - 184s - loss: 14.5219 - acc: 0.0990 - val_loss: 14.5303 - val_acc: 0.0985\n",
      "Epoch 2/50\n",
      "93184/93184 [==============================] - 181s - loss: 14.5212 - acc: 0.0991 - val_loss: 14.5303 - val_acc: 0.0985\n",
      "Epoch 3/50\n",
      "80300/93184 [========================>.....] - ETA: 22s - loss: 14.5268 - acc: 0.0987"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(len(train_Y), n_folds=5)\n",
    "for train, test in kf:\n",
    "    #print (train, test)\n",
    "    Tr_X = train_X[train]\n",
    "    Te_X = train_X[test]\n",
    "    Tr_Y = train_Y[train]\n",
    "    Te_Y = train_Y[test]\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    model.fit_generator(gen_Img.flow(Tr_X, Tr_Y, batch_size=100),\n",
    "                    samples_per_epoch=len(Tr_X), nb_epoch=50, validation_data=(Te_X, Te_Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 9)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 9)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 2)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 2)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 2)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 2)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 2)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 2)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 11)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 11)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 9)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 9)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 5)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 5)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 8)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 8)\n",
      "(array([[ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), '--><--', 10)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 10)\n"
     ]
    }
   ],
   "source": [
    "for x in range(100,1000,100):\n",
    "    print (model.predict(Te_X[x].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Te_Y[x]) )\n",
    "    print (model.predict_classes(Te_X[x].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Te_Y[x]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-9025865fa01f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTe_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTe_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         return self._test_loop(f, ins,\n\u001b[0;32m   1118\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m                                verbose=verbose)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Te_X, Te_Y, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the GPU memory\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict_proba(Te_X[3].reshape(1,img_channels,img_rows,img_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvNetFactory:\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(name, *args, **kargs):\n",
    "\t\t# define the network (i.e., string => function) mappings\n",
    "\t\tmappings = {\n",
    "\t\t\t\"shallownet\": ConvNetFactory.ShallowNet,\n",
    "\t\t\t\"lenet\": ConvNetFactory.LeNet,\n",
    "\t\t\t\"karpathynet\": ConvNetFactory.KarpathyNet,\n",
    "\t\t\t\"minivggnet\": ConvNetFactory.MiniVGGNet}\n",
    "\n",
    "\t\t# grab the builder function from the mappings dictionary\n",
    "\t\tbuilder = mappings.get(name, None)\n",
    "\n",
    "\t\t# if the builder is None, then there is not a function that can be used\n",
    "\t\t# to build to the network, so return None\n",
    "\t\tif builder is None:\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# otherwise, build the network architecture\n",
    "\t\treturn builder(*args, **kargs)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef ShallowNet(numChannels, imgRows, imgCols, numClasses, **kwargs):\n",
    "\t\t# initialzie the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first (and only) CONV => RELU layer\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# add a FC layer followed by the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef LeNet(numChannels, imgRows, imgCols, numClasses, activation=\"tanh\", **kwargs):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef KarpathyNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(16, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef MiniVGGNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
